{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bddc49ad-cee3-4ea3-b8c0-f86074704389",
   "metadata": {},
   "source": [
    "## Der Huffman Algorithmus\n",
    "\n",
    "David Huffman (1925-1999) entwickelte im Jahre 1952 ein Verfahren zur verlustlosen Kompression von Daten. \n",
    "Verlustlos bedeutet, dass die Ursprungsdaten nach der Kompression orginalgetreu wiederhergestellt \n",
    "werden können. \n",
    "Statt jedem Zeichen einen gleichlangen Code zuzuordnen (beispielweise 8 Bit im Falle von ASCII), bekommen Zeichen, die häufiger im Text vorkommen, einen kürzeren Code als seltene Zeichen.  \n",
    "\n",
    "Problematisch bei Codes mit unterschiedlichen Codewortlängen ist,  dass im allgemeinen eine eindeutige Dekodierung von Zeichenfolgen nicht möglich ist. Das ist Thema bei der folgenden Biber-Aufgabe\n",
    "\n",
    "<img src='BiberCode.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0fab4-1477-4d61-ba72-d9361ce8cbcb",
   "metadata": {},
   "source": [
    "### Fano-Bedingung\n",
    "Wenn kein Codewort Anfangswort eines anderen Codewortes ist,\n",
    "dann ist jede codierte Zeichenreihe eindeutig dekodierbar (Fano-Bedingung).\n",
    "\n",
    "Der Huffman-Algorithmus führt zu einer Codierung, die die Fano-Bedingung erfüllt und die\n",
    "beweisbar die größtmögliche Komprimierung erreicht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a254ea1-0b8c-441b-af30-ee7d261da764",
   "metadata": {},
   "source": [
    "### Beispiel\n",
    "\n",
    "Wir wollen das Wort *regenwetter* mit dem Huffman-Algorithmus codieren.  Dazu zählen wir, wie oft die verschiedenen Buchstaben in dem Text vorkommen. Wir betrachten das Ergebnis als eine Liste von Bäumen.  Von links gehen wir durch die Liste und suchen die beiden Bäume mit den kleinsten Zahlen in der Wurzel.  Das sind in unserem Fall die Bäume, an denen das g und das n hängen.  Diese werden linker und rechter Teilbaum eines neuen Baums, in dessen Wurzel wir die Summe der beiden Zahlen schreiben.  Der neue Baum wird rechts an die Liste angefügt. Die beiden benutzen Bäume verschwinden aus der Liste.\n",
    " \n",
    "\n",
    "<img src='baum1.png'>\n",
    "\n",
    "Wir wiederholen diesen Schritt, bis nur noch ein Baum übrigbleibt.\n",
    "\n",
    "\n",
    "<img src='baum2.png'>\n",
    "\n",
    "Wenn nur noch ein Baum vorhanden ist, können wir die Bitmuster für die Codierung der Zeichen ablesen. Abstieg in den linken Teilbaum ergibt 0, Abstieg in den rechten Teilbaum ergibt 1. Wir erhalten folgende Codierung:\n",
    "\n",
    "```\n",
    "t = 00, g = 010, n = 011, w = 100, r = 101, e = 11\n",
    "```\n",
    "\n",
    "Die Codierung von *regenwetter* hat eine Länge von 27 bit:\n",
    "```\n",
    "101110101101110011000011101\n",
    "```\n",
    "\n",
    "Bei der ASCII-Codierung wird jedes Zeichen mit 8 bit codiert. Für die 11 Buchstaben von *regenwetter* wären also 88 bit erforderlich. In der Huffman Codierung werden 61 bit, das sind ca. 69% der ursprünglichen Codierung eingespart.  \n",
    "\n",
    "Zur Dekodierung muss natürlich der verwendete Huffman-Baum zur Verfügung stehen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
